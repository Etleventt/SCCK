# lightning.pytorch==2.0.9.post0
seed_everything: 42

trainer:
  accelerator: gpu
  strategy: auto
  devices: [0,1]                 # 如需多卡改成 [0,1] 并将 use_distributed_sampler 设为 true
  num_nodes: 1
  precision: 32
  logger:
    - class_path: CSVLogger
      init_args:
        save_dir: logs
        name: experiment_nab
  callbacks:
    - class_path: lightning.pytorch.callbacks.TQDMProgressBar
      init_args:
        refresh_rate: 1
        leave: true
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        every_n_epochs: 10
        save_on_train_epoch_end: true
        save_top_k: -1
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
  max_epochs: 5000
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 0
  log_every_n_steps: 1
  deterministic: true
  inference_mode: true
  use_distributed_sampler: true
  sync_batchnorm: false

model:
  lr_g: 0.00016
  lr_d: 0.0001                    # 无判别器时忽略
  disc_grad_penalty_freq: 10       # 忽略
  disc_grad_penalty_weight: 0.5    # 忽略
  lambda_rec_loss: 0.5
  optim_betas: [0.5, 0.9]
  eval_mask: true
  eval_subject: true

  # —— 关键：关闭判别器 ——
  discriminator_params: null

  # —— 标准 SC 训练协议（同一 t 两次前向 + stop-grad + 逐样本 50% 置零）——
  use_standard_sc: true
  sc_prob: 0.5
  sc_stop_grad: true
  drop_r_prob: 0.0                 # SC 训练不走 r-loop，保持 0

  diffusion_params:
    n_steps: 10
    beta_start: 0.1
    beta_end: 3.0
    gamma: 1
    n_recursions: 2                # SC 路径不会用到 r-loop；保留原值即可
    consistency_threshold: 0.0

  generator_params:
    self_recursion: true
    image_size: ${data.image_size}
    z_emb_dim: 256
    ch_mult: [1, 1, 2, 2, 4, 4]
    num_res_blocks: 2
    attn_resolutions: [16]
    dropout: 0.0
    resamp_with_conv: true
    conditional: true
    fir: true
    fir_kernel: [1, 3, 3, 1]
    skip_rescale: true
    resblock_type: biggan
    progressive: none
    progressive_input: residual
    embedding_type: positional
    combine_method: sum
    fourier_scale: 16
    nf: 64
    num_channels: 2
    nz: 100
    n_mlp: 3
    centered: true
    not_use_tanh: false

data:
  train_batch_size: 100            # SC 训练两次前向，建议比基线略小
  val_batch_size: 100
  test_batch_size: 1024
  dataset_dir: /home/xiaobin/Projects/SelfRDB/dataset/brats64_selfrdb_clean_copy_withmask
  source_modality: t1
  target_modality: t2
  dataset_class: NumpyDataset
  image_size: 64
  padding: false
  norm: true
  num_workers: 8

ckpt_path:

